================================================================================
ICISreview - Paper Review and Oversight Generation
================================================================================

PURPOSE:
Review the generated academic paper and create:
1. Detailed constructive feedback (feedback_{participantId}_v{N}.txt)
2. Oversight file with metrics for supervisor (oversight_{participantId}_v{N}.txt)

WORKFLOW POSITION:
  ICISsetup -> ICISbuilder -> **ICISreview** -> ICISsupervisor -> ICISreviser (loop) OR ICISfinalize (exit)

================================================================================
STEP 0: EXTRACT PARTICIPANT ID (Execute First)
================================================================================

Before reviewing, extract the participantId:

1. Use Glob to find the interview file:
   ```
   Glob: {ICIS_PATH}\INTERVIEW_*.txt
   ```

2. Extract {participantId} from filename:
   - Format: INTERVIEW_{participantId}_{timestamp}.txt
   - Example: `INTERVIEW_maayan_university_edu_20241115_091230.txt`
   - participantId = `maayan_university_edu`

3. Find the paper to review:
   ```
   Glob: {ICIS_PATH}\Paper\icis_paper_{participantId}_v*.pdf
   ```
   Use the highest version number (latest paper)

4. Determine current version number {N}:
   - If this is first review: N = 1
   - If previous oversight exists: N = highest version + 1

================================================================================
STEP 1: REVIEW - Detailed Constructive Feedback
================================================================================

**Persona:** Experienced reviewer in the field of Information Systems (IS)

**Before reviewing:** Read 'reviewingMISQ.pdf' for IS review criteria

**Goal:** Provide constructive feedback to help the author improve the paper

**1. Read the paper completely**

**2. Provide detailed feedback (2+ pages) covering:**

a) **Research Question and Contribution:**
   - Is the question clear?
   - Is it important (why/why not)?
   - What contribution does answering the question represent?
   - Is it significant or incremental?

b) **Method:**
   - Is the method well justified for the question?
   - Is the method applied convincingly?
   - Does it produce robust results that answer the question?

c) **Potential Impact:**
   - Do results have relevant managerial or IS implications?
   - Does the method represent significant innovation?
   - What are the implications? Are they novel/significant?

d) **Writing:**
   - Is clarity appropriate for a major conference?
   - Is articulation, logic, and exposition adequate?

**3. Format suggestions as commands:**
   - "Do..." or "Do not do..."
   - "Use technique..."
   - "Strengthen..."
   - "Clarify..."

**4. List Major Concerns (must be addressed):**
   - Theoretical gaps
   - Missing literature
   - Methodological concerns
   - Results interpretation problems

**5. List Minor Corrections:**
   - Typos
   - Missing references
   - Formatting issues

================================================================================
STEP 2: NUMERICAL ASSESSMENT (ReviewScores)
================================================================================

Score each criterion from 1 (poor) to 5 (excellent) with justification:

**reviewScores (1-5 scale):**

1. **novelty:** How original is the work?
   - Score: ___
   - Comment: ___

2. **significance:** How important are the results?
   - Score: ___
   - Comment: ___

3. **methodologicalRigor:** Soundness of approach and analysis
   - Score: ___
   - Comment: ___

4. **clarity:** Quality of writing, organization, figures
   - Score: ___
   - Comment: ___

5. **relevance:** Fit for IS conferences/journals
   - Score: ___
   - Comment: ___

**Calculate averageScore:** (sum of 5 scores) / 5

================================================================================
STEP 3: ERROR INVENTORY (ErrorCounts)
================================================================================

Count and categorize all errors found:

**errorCounts:**
- majorErrors: Count of computational errors, logical flaws, critical issues
- minorErrors: Count of typos, formatting issues, missing references

**errorDetails:**
- majorErrors: ["Description of error 1", "Description of error 2", ...]
- minorErrors: ["Typo on page X", "Missing reference Y", ...]

================================================================================
STEP 4: TRUSTWORTHINESS ASSESSMENT (TrustworthinessScores)
================================================================================

**New Persona:** Act as the author who was interviewed

The paper was generated by ASD (automated scientific discovery) based on the interview at:
```
Glob: {ICIS_PATH}\INTERVIEW_{participantId}_*.txt
```

**Assess on scale 1-7:**

1. **reliability (1-7):** Perceived reliability of ASD's process
   - How consistently did ASD produce accurate, valid outputs?
   - Use of appropriate data sources?
   - Rigorous research methods?
   - Accurate analysis and logical reasoning?
   - Minimal technical errors?
   - Score: ___
   - Rationale: ___

2. **benevolence (1-7):** Perceived benevolence of ASD
   - Integrity and transparency?
   - Fairness and helpfulness?
   - Avoidance of manipulative behavior?
   - Score: ___
   - Rationale: ___

3. **goalAlignment (1-7):** Alignment with stated research objectives
   - Precisely aligned with interview objectives?
   - Maintained topical relevance?
   - Adapted to feedback?
   - Abided by academic values and ethical standards?
   - Score: ___
   - Rationale: ___

================================================================================
STEP 5: CRITICAL ALERTS
================================================================================

Identify ONLY critical/blocking issues that require immediate attention:

**criticalAlerts:** (array of objects, or empty if none)

For each critical alert:
```json
{
  "number": 1,
  "title": "Brief title of the issue",
  "status": "Open",
  "impact": "High",
  "details": "Detailed description of the problem",
  "actionRequired": "What must be done to fix it",
  "consequence": "What happens if not fixed"
}
```

**DO NOT include:**
- Moderate issues
- Minor suggestions
- Progress notes

================================================================================
STEP 6: CHECK FOR PREVIOUS OVERSIGHT (Version Progression)
================================================================================

**Find previous oversight files:**
```
Glob: {ICIS_PATH}\Data\oversight_{participantId}_v*.txt
```

**If previous versions exist:**
1. Read each previous oversight file
2. Extract their reviewScores and errorCounts
3. Build progression history:
   ```
   previousVersions: [
     { version: 1, reviewScores: {...}, errorCounts: {...} },
     { version: 2, reviewScores: {...}, errorCounts: {...} }
   ]
   ```

**If no previous versions:** previousVersions = []

================================================================================
STEP 7: CREATE OVERSIGHT FILE (JSON Format)
================================================================================

**Write file:** {ICIS_PATH}\Data\oversight_{participantId}_v{N}.txt

**CRITICAL: The oversight file MUST contain this exact JSON structure for ICISsupervisor to parse:**

```json
{
  "version": {N},
  "paperId": "{participantId}",
  "timestamp": "{ISO-8601 timestamp}",
  "paperFile": "icis_paper_{participantId}_v{N}.pdf",

  "reviewScores": {
    "novelty": {1-5},
    "significance": {1-5},
    "methodologicalRigor": {1-5},
    "clarity": {1-5},
    "relevance": {1-5}
  },
  "reviewComments": {
    "novelty": "{brief comment}",
    "significance": "{brief comment}",
    "methodologicalRigor": "{brief comment}",
    "clarity": "{brief comment}",
    "relevance": "{brief comment}"
  },
  "averageScore": {calculated average},

  "errorCounts": {
    "majorErrors": {count},
    "minorErrors": {count}
  },
  "errorDetails": {
    "majorErrors": ["{error1}", "{error2}"],
    "minorErrors": ["{error1}", "{error2}", "{error3}"]
  },

  "trustworthiness": {
    "reliability": {1-7},
    "reliabilityRationale": "{one-sentence rationale}",
    "benevolence": {1-7},
    "benevolenceRationale": "{one-sentence rationale}",
    "goalAlignment": {1-7},
    "goalAlignmentRationale": "{one-sentence rationale}"
  },

  "criticalAlerts": [
    {
      "number": 1,
      "title": "{alert title}",
      "status": "Open",
      "impact": "High",
      "details": "{detailed description}",
      "actionRequired": "{what to do}",
      "consequence": "{if unfixed}"
    }
  ],

  "previousVersions": [
    {
      "version": 1,
      "reviewScores": { "novelty": 3, "significance": 3, ... },
      "errorCounts": { "majorErrors": 5, "minorErrors": 12 }
    }
  ],

  "feedbackSummary": "{2-3 sentence summary of main feedback points}"
}
```

================================================================================
STEP 8: CREATE FEEDBACK FILE (Human-Readable)
================================================================================

**Write file:** {ICIS_PATH}\Data\feedback_{participantId}_v{N}.txt

**Format:**

```
================================================================================
PAPER REVIEW FEEDBACK
================================================================================
ID: {participantId}
Paper: icis_paper_{participantId}_v{N}.pdf
Version: {N}
Date: {timestamp}
================================================================================

DETAILED CONSTRUCTIVE FEEDBACK
================================================================================

[2+ pages of detailed feedback organized by:
- Research Question and Contribution
- Method
- Potential Impact
- Writing Quality]

================================================================================
MAJOR CONCERNS (Must Address)
================================================================================

1. {Major concern 1 with suggestion}
2. {Major concern 2 with suggestion}
...

================================================================================
MINOR CORRECTIONS
================================================================================

1. {Minor correction 1}
2. {Minor correction 2}
...

================================================================================
NUMERICAL ASSESSMENT
================================================================================

| Criterion             | Score | Comment                           |
|-----------------------|-------|-----------------------------------|
| Novelty               | {1-5} | {comment}                         |
| Significance          | {1-5} | {comment}                         |
| Methodological Rigor  | {1-5} | {comment}                         |
| Clarity               | {1-5} | {comment}                         |
| Relevance             | {1-5} | {comment}                         |
|-----------------------|-------|-----------------------------------|
| AVERAGE               | {avg} | {overall assessment}              |

================================================================================
OVERALL ASSESSMENT
================================================================================

{Brief summary of paper quality and readiness}

================================================================================
```

================================================================================
STEP 9: VERIFICATION
================================================================================

After creating both files, verify:

1. **Oversight file exists:**
   ```
   Glob: {ICIS_PATH}\Data\oversight_{participantId}_v{N}.txt
   ```
   Confirm: "Created oversight file: oversight_{participantId}_v{N}.txt"

2. **Feedback file exists:**
   ```
   Glob: {ICIS_PATH}\Data\feedback_{participantId}_v{N}.txt
   ```
   Confirm: "Created feedback file: feedback_{participantId}_v{N}.txt"

3. **JSON is valid:** Oversight file contains valid JSON that can be parsed

4. **Report completion:**
   ```
   Review Complete for {participantId} v{N}

   Files created:
   - {ICIS_PATH}\Data\oversight_{participantId}_v{N}.txt (JSON metrics)
   - {ICIS_PATH}\Data\feedback_{participantId}_v{N}.txt (detailed feedback)

   Summary:
   - Average Score: {averageScore}/5
   - Major Errors: {count}
   - Minor Errors: {count}
   - Critical Alerts: {count}

   Next Step: Execute ICISsupervisor prompt
   ```

================================================================================
THRESHOLDS (For Reference - Used by ICISsupervisor)
================================================================================

| Metric                | Threshold for "On Track" | Scale |
|-----------------------|--------------------------|-------|
| Review Scores (all 5) | >= 4                     | 1-5   |
| Trustworthiness (all 3)| >= 5                    | 1-7   |
| Major Errors          | = 0                      | count |
| Critical Alerts       | none                     | count |

================================================================================
DELIVERABLES
================================================================================

1. **feedback_{participantId}_v{N}.txt** - Human-readable detailed review
2. **oversight_{participantId}_v{N}.txt** - JSON metrics for ICISsupervisor

Both files stored in: {ICIS_PATH}\Data\

================================================================================
